{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/JHI_STRAP_Web.png\" style=\"width: 150px; float: right;\">\n",
    "# 01b - Classifiers (15min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Biological Motivation](#motivation)\n",
    "2. [Performance Metrics and Contingency Tables](#contingency)\n",
    "3. [Classifier Performance](#performance)\n",
    "4. [Baseline Frequency](#baseline)\n",
    "5. [Bayes' Theorem](#bayes)\n",
    "6. [Real-World Example](#example)\n",
    "7. [Comments](#comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"motivation\"></a>\n",
    "## 1. Biological motivation\n",
    "\n",
    "<p></p><div class=\"alert-info\">\n",
    "You are interested in a predicted gene coding region on a newly-sequenced genome, and want to know if its protein product belongs to a particular functional class of proteins (RxLR effector proteins).\n",
    "<br></br><br></br>\n",
    "You have access to a software tool that *classifies* proteins as `effector` or `not effector`.\n",
    "</div>\n",
    "\n",
    "<img src=\"images/exercise.png\" style=\"width: 50px; float: left;\">\n",
    "### QUESTION:  (2min)\n",
    "\n",
    "<p></p><div class=\"alert-danger\">\n",
    "<b>If the software tool says that the protein product is an effector, should you believe the prediction?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contingency\"></a>\n",
    "## 2. Performance Metrics and Contingency Tables\n",
    "\n",
    "<p></p><div class=\"alert-success\">\n",
    "<b>We consider *classifier tools* that decide whether an input belongs to a *class*, or does not belong to that class. This is a *binary classifier*.</b>\n",
    "</div>\n",
    "\n",
    "The performance of *binary classifier tools* is typically measured on a *test set* of data, which can be called a member of the *class* (`positive`) or not a member (`negative`). Calculations of four values can be made:\n",
    "\n",
    "* **True Positives** (TP): the number of `positive` examples that the classifer correctly assigns as `positive`\n",
    "* **True Negatives** (TN): the number of `negative` examples that the classifer correctly assigns as `negative`\n",
    "* **False Positives** (FP): the number of `negative` examples that the classifer incorrectly assigns as `positive`\n",
    "* **False Negatives** (FN): the number of `positive` examples that the classifer incorrectly assigns as `negative`\n",
    "\n",
    "These are often represented as *contingency tables* or a *confusion matrix*:\n",
    "\n",
    "![Confusion Matrix](images/confusion_matrix.png)\n",
    "\n",
    "These values can be combined into a number of useful *performance metrics* that summarise the *classifier*'s ability to perform particular tasks.\n",
    "\n",
    "* **Sensitivity** (Sn, true positive rate, TPR): The proportion of `positive` examples that are correctly classified\n",
    "\n",
    "$$\\textrm{Sensitivity (Sn)} = \\frac{\\textrm{TP}}{(\\textrm{TP} + \\textrm{FN})}$$\n",
    "\n",
    "* **Specificity** (Sp, true negative rate, TNR): The proportion of `negative` examples that are correctly classified\n",
    "\n",
    "$$\\textrm{Specificity (Sp)} = \\frac{\\textrm{TN}}{(\\textrm{FP} + \\textrm{TN})}$$\n",
    "\n",
    "* **False Positive Rate** (FPR, $1 - \\textrm{Sp}$): The proportion of `negative` examples incorrectly classed as `positive`.\n",
    "\n",
    "$$\\textrm{FPR} = \\frac{\\textrm{FP}}{(\\textrm{FP} + \\textrm{TN})}$$\n",
    "\n",
    "<p></p><div class=\"alert-warning\">\n",
    "<b>If you do not have this information, you cannot interpret predictive results!</b>\n",
    "</div>\n",
    "\n",
    "![SMBC False Positive Comic](images/1468070206-20160709.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"performance\"></a>\n",
    "## 3. Classifier Performance\n",
    "\n",
    "<p></p><div class=\"alert-success\">\n",
    "<b>In our example, we assume that our functional classifier that determines whether a protein sequence is likely to be that of an effector has the following *performance metrics*:</b>\n",
    "</div>\n",
    "\n",
    "* **Sensitivity**: Sn = 0.95\n",
    "* **False Positive Rate**: FPR = 0.01\n",
    "\n",
    "<img src=\"images/exercise.png\" style=\"width: 50px; float: left;\">\n",
    "### QUESTION:  (2min)\n",
    "\n",
    "<p></p><div class=\"alert-danger\">\n",
    "<b>Do you think these are good performance characteristics?</b>\n",
    "</div>\n",
    "\n",
    "<p></p><div class=\"alert-info\">\n",
    "<b>The classifier says your protein is an effector!</b>\n",
    "</div>\n",
    "\n",
    "<img src=\"images/exercise.png\" style=\"width: 50px; float: left;\">\n",
    "### QUESTION:  (2min)\n",
    "\n",
    "<p></p><div class=\"alert-danger\">\n",
    "<b>What is the probability that your protein is really an effector?\n",
    "<b>0.01, 0.05, 0.50, 0.95, 0.99</b>\n",
    "</ul></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"baseline\"></a>\n",
    "## 4. Baseline Frequency\n",
    "\n",
    "<p></p><div class=\"alert-success\">\n",
    "<b>Unless you know the baseline occurrence of a class in the set of inputs, you cannot calculate the probability that the classifier is correct in any particular case.</b>\n",
    "</div>\n",
    "\n",
    "Denoting the *baseline occurrence*, or *baseline frequency* (the proportion of all proteins that are effectors) with which a protein may be an effector as $f_{x}$: \n",
    "\n",
    " $$f_{x} = 0.01 \\implies P(\\textrm{effector}|\\textrm{+ve}) = 0.490 \\approx 0.5$$\n",
    " $$f_{x} = 0.8 \\implies P(\\textrm{effector}|\\textrm{+ve}) = 0.997 \\approx 1.0$$\n",
    " \n",
    "<p></p><div class=\"alert-warning\">\n",
    "<b>If effectors are *rare*, the functional classification is more likely to be false</b>\n",
    "</div>\n",
    "\n",
    "<img src=\"images/exercise.png\" style=\"width: 50px; float: left;\">\n",
    "### QUESTION:  (2min)\n",
    "\n",
    "<p></p><div class=\"alert-danger\">\n",
    "<b>You run the classifier tool on 20,000 proteins from your favourite organism. You expect around 200 of these proteins to be effectors.</b>\n",
    "<br></br><br></br>\n",
    "<b>What is the approximate probability that any individual classification is correct?</b>\n",
    "<br></br><br></br>\n",
    "<b>BONUS: Approximately how many positive classifications would you expect?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bayes\"></a>\n",
    "## 5. Bayes' Theorem\n",
    "\n",
    "<p></p><div class=\"alert-success\">\n",
    "<b>The relatively low probability of any classification being correct, even if the classifier has excellent performance metrics, can be counterintuitive. But we can always understand the statistics using Bayes' Theorem</b>\n",
    "</div>\n",
    "\n",
    "With:\n",
    "\n",
    "* $P(\\textrm{positive})$ = the expected proportion of `positive` examples (the *baserate*)\n",
    "* $P(\\textrm{negative})$ = the expected proportion of `negative` examples\n",
    "* $P(+|\\textrm{positive})$ = the probability the classifier calls `positive`, if the example is `positive` (TPR, Sn)\n",
    "* $P(+|\\textrm{negative})$ = the probability the classifier calls `positive`, if the example is `negative` (FPR)\n",
    "\n",
    "The probability that an example is `positive`, given the classifier says that it is `positive` is $P(\\textrm{positive}|+)$ and can be calculated:\n",
    "\n",
    "$$P(\\textrm{positive}|+) = \\frac{P(+|\\textrm{positive})P(\\textrm{positive})}{P(+|\\textrm{positive})P(\\textrm{positive}) + P(+|\\textrm{negative})P(\\textrm{negative})}$$\n",
    "\n",
    "<p></p><div class=\"alert-warning\">\n",
    "<b>We can visualise how the probability of a positive classification being correct ($P(\\textrm{eff}|\\textrm{pos})$) varies with baserate, using the Python code in the cell below:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Â Import Python libraries\n",
    "%matplotlib inline\n",
    "import seaborn as sns         # This produces pretty graphical output\n",
    "import tools.classifier as tc # This lets us plot some classifer-specific visualisation\n",
    "\n",
    "# Define sensitivity and FPR\n",
    "sn = 0.90    # sensitivity\n",
    "fpr = 0.05   # false positive rate\n",
    "\n",
    "# Define baserate (frequency of positive examples)\n",
    "baserate = 0.3\n",
    "\n",
    "# Static plot of \n",
    "tc.plot_prob_effector(sn, fpr, baserate);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, we see the effector classifier's response curve (red line) as a function of baserate, assuming it has a 90% *sensitivity*, and a 5% *false positive rate*.\n",
    "\n",
    "The black arrow points at a particular response rate - when the baserate of positives in the population is 30%. At this point, any positive classification has about 89% probability of really being a positive example.\n",
    "\n",
    "<p></p><div class=\"alert-warning\">\n",
    "<b>\n",
    "So long as about 20% of all proteins are effectors, the classifier predictions are correct about 80% of the time.\n",
    "<br></br><br></br>\n",
    "As the baserate drops below about 7%, predictions are more likely to be incorrect, rather than correct.\n",
    "</b>\n",
    "</div>\n",
    "\n",
    "<img src=\"images/exercise.png\" style=\"width: 50px; float: left;\">\n",
    "### QUESTION:  (4min)\n",
    "\n",
    "<p></p><div class=\"alert-danger\">\n",
    "<b>What is the probability that a positive result from our fictional classifier (Sn=0.95, FPR=0.01) is correct, with baserate 0.01?</b>\n",
    "<br></br><br></br>\n",
    "<b>What if the sensitivity falls to 90%, and the FPR increases to 5%?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p><div class=\"alert-success\">\n",
    "<b>In the cell below you can see code that renders an interactive version of the plot above, which allows you to vary the sensitivity, false positive rate, and baserate of positive examples using sliders. You can also zoom in to the left-hand region of the graph for clarity.</b>\n",
    "</div>\n",
    "\n",
    "<a id=\"example\"></a>\n",
    "## 6. Real-World Example\n",
    "\n",
    "<p></p><div class=\"alert-info\">\n",
    "In their 2009 paper, Arnold *et al.* describe a tool to predict bacterial Type III effector proteins called `EffectiveT3`. This tool is reported with sensitivity 71% and selectivity 85% (thus FPR is 15%).\n",
    "</div>\n",
    "\n",
    "* [Arnold *et al.* (2009) \"Sequence-based prediction of type III secreted proteins\" *PLoS Pathog.* 5 e1000376 doi:10.1371/journal.ppat.1000376](http://dx.doi.org/10.1371/journal.ppat.1000376)\n",
    "\n",
    "In their paper, the authors identify hundreds of type III effectors in genomes that possess no annotated type III secretion system (over 10% of the complete protein complement, in some cases). They note:\n",
    "\n",
    "> The surprisingly high number of (false) positives in genomes without TTSS exceeds the expected false positive rate (Table 1) and thus raised questions about their nature.\n",
    "\n",
    "<img src=\"images/exercise.png\" style=\"width: 50px; float: left;\">\n",
    "### QUESTION:  (4min)\n",
    "\n",
    "<p></p><div class=\"alert-danger\">\n",
    "<b>What is the expected probability that a positive prediction from `EffectiveT3` is really a type III effector, given that *Pseudomonas syringae* possesses fewer than 100 effectors in a 5000-gene genome (baserate <â 3%)?</b>\n",
    "<br></br><br></br>\n",
    "Why do you think the authors saw so many likely false positives?\n",
    "<br></br><br></br>\n",
    "How do you think you might be able to improve the probability that a positive prediction/classification is a real positive example, when making predictions/classifying all proteins on a genome?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "from ipywidgets import interact, FloatSlider  # for interactive widgets\n",
    "\n",
    "# Define sensitivity and FPR\n",
    "sn = 0.90    # sensitivity\n",
    "fpr = 0.05   # false positive rate\n",
    "\n",
    "# Define baserate (frequency of positive examples)\n",
    "baserate = 0.3\n",
    "\n",
    "# Create an interactive plot \n",
    "interact(tc.plot_prob_effector,\n",
    "         sens=FloatSlider(min=0.01, max=0.99, step=0.01, value=sn), \n",
    "         fpr=FloatSlider(min=0.01, max=0.99, step=0.01, value=fpr),\n",
    "         baserate=FloatSlider(min=0.01, max=0.99, step=0.01, value=baserate),\n",
    "         xmax=FloatSlider(min=0.1, max=1, step=0.1, value=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comments\"></a>\n",
    "## 7. Comments\n",
    "\n",
    "### 1. Predictions/Classifiers Identify Groups, Not Individuals\n",
    "\n",
    "Predictors and classifiers identify groups of positive/negative examples, not individual members of the group. For example, if a test for smugglers at an airport has $P(\\textrm{smuggler}|+) = 0.9$ and 100 potential smugglers are identified, how do we tell which 10 smugglers are wrongly identified? We always need more evidence to distinguish within the predicted group members.\n",
    "\n",
    "### 2. Stratification Can Improve Classifier Performance\n",
    "\n",
    "If there are a set of criteria that an example must meet in order to be a member of a class, then excluding all examples that do not meet these criteria reduces the scope for false positives, and raises the *baserate*, increasing the probability that a positive classification implies a positive example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
